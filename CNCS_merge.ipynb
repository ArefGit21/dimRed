{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNCS-merge",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArefGit21/dimRed/blob/master/CNCS_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drbGQ2rSivZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dff90eb-dac9-4eed-8d77-972be5df5c80"
      },
      "source": [
        "!pip install boto3\n",
        "!pip install nipype\n",
        "!pip install nilearn\n",
        "!pip install catboost\n",
        "!pip install nibabel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAZIkRI46GgX"
      },
      "source": [
        "**Import Required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on2S7kACsD9p"
      },
      "source": [
        "import boto3\n",
        "import re\n",
        "import os\n",
        "from nilearn import datasets\n",
        "import requests\n",
        "from nilearn.decomposition import CanICA\n",
        "import numpy as np\n",
        "import nibabel as nb\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwkIfHkY5yQK"
      },
      "source": [
        "**Download Data from HCP Server via s3 Amazon**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOnhJmz5Uhxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26a7b04-33c0-43be-cc53-840199917b6c"
      },
      "source": [
        "\n",
        "access_key = 'AKIAXO65CT57EQTONEGA'\n",
        "secret_key = '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'\n",
        "\n",
        "\n",
        "def ensure_dir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  s3_client = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
        "  s3_resource = boto3.resource('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
        "  dataset = 'HCP_1200/'\n",
        "  pattern = 'HCP_1200\\/[0-9]+\\/MNINonLinear\\/Results\\/rfMRI_REST1_LR\\/rfMRI_REST1_LR.nii.gz'\n",
        "  bucket = s3_resource.Bucket('hcp-openaccess')\n",
        "  s3_keys = bucket.objects.filter(Prefix=dataset)\n",
        "  s3_keylist = []\n",
        "  n_subjects = 5\n",
        "  counter = 0\n",
        "  print('Listing starts ...')\n",
        "  for key in s3_keys:\n",
        "    if re.fullmatch(pattern, key.key):\n",
        "      counter +=1\n",
        "      s3_keylist.append(key.key)\n",
        "      if counter>= n_subjects:\n",
        "        break\n",
        "  print('Listing finished')\n",
        "  print('Downloading starts ...')\n",
        "  s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
        "  for key in s3_keylist:\n",
        "    print(key)\n",
        "    path = key.replace('/', os.sep)\n",
        "    ensure_dir(path)\n",
        "    with open(path, 'wb') as data:\n",
        "        s3.download_fileobj('hcp-openaccess', key, data)\n",
        "  print('Downloading finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Listing starts ...\n",
            "Listing finished\n",
            "Downloading starts ...\n",
            "HCP_1200/100206/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
            "HCP_1200/100307/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
            "HCP_1200/100408/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
            "HCP_1200/100610/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
            "HCP_1200/101006/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
            "Downloading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7c8mqtsxiev"
      },
      "source": [
        "**Load Data & Listing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Qv3Zgmkc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2fb46d-16d1-444f-87b0-1c8da58307a7"
      },
      "source": [
        "#LOAD files & Listing\n",
        "imgcounter=0\n",
        "subject_list=[]\n",
        "subject_dataobj_list=[]\n",
        "subject_header_list=[]\n",
        "subject_ids = []\n",
        "for subdir, dirs, files in os.walk(r'HCP_1200'):\n",
        "    for filename in files:\n",
        "        subject_ids.append(subdir[9:15])\n",
        "        filepath = subdir + os.sep + filename\n",
        "        imgcounter+=1\n",
        "        print(\"------------imgcounter=\",imgcounter,\"------------\") #counter debuger\n",
        "        print(\"Path:\",filepath) #file path debuger\n",
        "        imgfile = os.path.join(filepath)\n",
        "        img = nb.load(imgfile)\n",
        "        subject_list.append(img)\n",
        "        subject_dataobj_list.append(img.dataobj)\n",
        "        print(\"subject_list:\",subject_list) #subject list debuger\n",
        "        subject_header_list.append(img.header)\n",
        "        print(\"subject_header_list:\",subject_header_list) #header dubuger\n",
        "        print(\"subject_dataobj_list:\",subject_dataobj_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
         
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKG7YLP5Kvc"
      },
      "source": [
        "\n",
        "**ICA : Deriving Independent Components**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwZwE7EjCgn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6367a537-0841-4c99-d1cd-ddae7437f4bd"
      },
      "source": [
        "#check with sample data from nilearn dataset\n",
        "\"\"\"rest_dataset = datasets.fetch_development_fmri(n_subjects=10)\n",
        "func_filenames = rest_dataset.func  # list of 4D nifti files for each subject\n",
        "print(func_filenames)\n",
        "# print basic information on the dataset\n",
        "print('First functional nifti image (4D) is at: %s' %\n",
        "      rest_dataset.func[0])  # 4D data\n",
        "    img = ICASAF(func_filenames)  \"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"rest_dataset = datasets.fetch_development_fmri(n_subjects=10)\\nfunc_filenames = rest_dataset.func  # list of 4D nifti files for each subject\\nprint(func_filenames)\\n# print basic information on the dataset\\nprint('First functional nifti image (4D) is at: %s' %\\n      rest_dataset.func[0])  # 4D data\\n    img = ICASAF(func_filenames)  \""
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S5OOAn9jNGw"
      },
      "source": [
        "def ICASAF (x):\n",
        "  from nilearn.decomposition import CanICA\n",
        "  canica = CanICA(n_components=20,\n",
        "                memory=\"nilearn_cache\", memory_level=2,\n",
        "                verbose=10,\n",
        "                mask_strategy='template',\n",
        "                random_state=0)\n",
        "  return np.asanyarray(canica.fit_transform(x))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7sMXSLwtejK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e44e95-a6c0-40fe-f921-569226bdf09b"
      },
      "source": [
        "subject_list = ICASAF(subject_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MultiNiftiMasker.fit] Loading data from [Nifti1Image('HCP_1200/102311/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            " Nifti1Image('HCP_1200/102008/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            " Nifti1Image('HCP_1200/103010/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            " Nifti1Image('HCP_1200/102715/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            " Nifti1Image('HCP_1200/103212/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            " Nifti1Image('HCP_1200/102816/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'),\n",
            
            "[MultiNiftiMasker.fit] Computing mask\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asxwE_pmjt6_"
      },
      "source": [
        "subject_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQZB69EV5QcC"
      },
      "source": [
        "\n",
        "**MODEL AND CROSS VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrvB_e-bqbrK"
      },
      "source": [
        "url = 'https://drive.google.com/uc?id=1BbZugD99dpsM_OotT9OljOagIby3K7bX&export=download'\n",
        "label = pd.read_csv(url,error_bad_lines=False)\n",
        "label = label[['Subject','Gender']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjum7TCzrd80"
      },
      "source": [
        "subject_ids = list(map(int, subject_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m35T1C6AnKKH"
      },
      "source": [
        "label=label[label['Subject'].apply(lambda x: x in subject_ids)]\n",
        "label['Gender'] = label['Gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
        "label = label['Gender']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-hQh3FJuNXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "d5ad57dc-fb6e-4803-d189-392d293e2e3a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(img.reshape(10,-1), label, test_size=0.30, random_state=42)\n",
        "\n",
        "model = CatBoostClassifier(iterations=2,\n",
        "                           depth=2,\n",
        "                           learning_rate=1,\n",
        "                           loss_function='Logloss',\n",
        "                           verbose=True)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0tcgN8_ttHc"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "print(f\"Accuracy of model: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
